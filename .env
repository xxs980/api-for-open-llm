# model related

# PORT=6001
# HOST = 192.168.10.254
# MODEL_NAME=qwen
# MODEL_PATH=/mnt/data1/llm_models/Qwen-7B-Chat

# PORT=6002
# HOST = 192.168.10.254
# MODEL_NAME=baichuan
# MODEL_PATH=/mnt/data1/llm_models/Baichuan-13B-Chat

# PORT=6003
# HOST = 192.168.10.254
# MODEL_NAME=chatglm2
# MODEL_PATH=/mnt/data1/llm_models/chatglm2-6b

PORT=6005
HOST=0.0.0.0
MODEL_NAME=baichuan
MODEL_PATH=/mnt/data1/llm_models/internlm-chat-7b-v1_1
# internlm-chat-7b-v1_1
# Baichuan-13B-Chat
EMBEDDING_NAME=/home/zhoupengzhen/data/checkpoints/m3e-base
ADAPTER_MODEL_PATH=
QUANTIZE=16
CONTEXT_LEN=
LOAD_IN_8BIT=false
LOAD_IN_4BIT=false
USING_PTUNING_V2=false
STREAM_INTERVERL=2
PROMPT_NAME=

USE_VLLM=true
TRUST_REMOTE_CODE=true

# device related
DEVICE=cuda
DEVICE_MAP=
GPUS=1,2
NUM_GPUs=2
TENSOR_PARALLEL_SIZE=2

# patch related
PATCH_TYPE=
TRAINING_LENGTH=4096
WINDOW_SIZE=512

# api related
API_PREFIX=/v1
